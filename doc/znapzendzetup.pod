=head1 NAME

znapzendzetup - znapzend setup utility

=head1 SYNOPSIS

B<znapzendzetup> I<command> [I<common-options...>] [I<command-options...>]

where 'common-options' (must precede command-options) is a mix of the
following:

            [--rootExec={pfexec|sudo}] \
            [--features={x,y,...}] \
                {lowmemRecurse zfsGetType} \
            [--debug]

and where 'command' and its unique options is one of the following:

    create  [--recursive] [--mbuffer=<path>[:<port>]] [--mbuffersize=<size>] \
            [--pre-snap-command=<command>] \
            [--post-snap-command=<command>] \
            [--tsformat=<format>] --donotask \
            [--send-delay=<time>] \
            SRC plan dataset [src_mbuffer_path [src_mbuffer_size]] \
            [ DST[:key] plan [[user@]host:]dataset
                [pre-send-command] [post-send-command] \
                [dst_mbuffer_path[:port]] [dst_mbuffer_size] ]

            NOTE: If you specify [user@]host:dataset for remote replication
            over SSH, make use of ~/.ssh/config for any advanced options
            (custom ports, keys to use, etc.) See znapzend README for ideas.

    delete  [--dst=key] <src_dataset>

    edit    [--recursive=on|off] \
            [--mbuffer=<path>[:<port>]|off] [--mbuffersize=<size>] \
            [--pre-snap-command=<command>|off] \
            [--post-snap-command=<command>|off] \
            [--tsformat=<format>] --donotask \
            [--send-delay=<time>] \
            SRC [plan] dataset [src_mbuffer_path [src_mbuffer_size]] \
            [ DST:key [plan] [dataset] \
                [pre-send-command|off] [post-send-command|off] \
                [dst_mbuffer_path[:port]|off] [dst_mbuffer_size] ]

    edit    <src_dataset>

    enable  <src_dataset>

    disable <src_dataset>

    enable-dst  <src_dataset> <DST_key>

    disable-dst <src_dataset> <DST_key>

    enable-dst-autocreation  <src_dataset> <DST_key>

    disable-dst-autocreation <src_dataset> <DST_key>

    inherit-dst-autocreation  <src_dataset> <DST_key>

    list    [--recursive] [--inherited] [src_dataset...]

    export  <src_dataset>

    import  [--write] [--prop <property>=<value>, [--prop ...] ...]
            <src_dataset> [<prop_dump_file>]

    help

    man

=head1 DESCRIPTION

Use znapzendsetup to configure your backup tasks. The cli is modled after
the zfs commandline.

After modifying the configuration, send a HUP signal to your znapzend daemon
for it to re-read the configuration.

Common options include:

=over

=item B<--features>=I<feature1>,I<feature2>,...

enables a few enhanced zfs module features to be on par with those used by
the znapzend command (but far fewer are relevant for the znapzendzetup)

Available features:

=over

=item lowmemRecurse

use 'lowmemRecurse' on systems where you have too many datasets,
so a recursive listing of attributes to find backup plans exhausts
the memory available to `znapzend(zetup)`: instead, go the slower
way to first list all impacted dataset names, and then query their
configs one by one.

=item zfsGetType

use 'zfsGetType' if your 'zfs get' supports a '-t' argument for
filtering by dataset type at all (e.g. one in Solaris 10 does not),
AND lists properties for snapshots by default when recursing (e.g.
the one in Solaris 10u8 already does), so that there is too much
data to process while searching for backup plans.

If these two conditions apply to your system, the time needed for
a '--recursive' listing of backup plans can literally differ by
hundreds of times (depending on the amount of snapshots in that
dataset tree... and a decent backup plan will ensure you have a
lot of those), so you would benefit from requesting this feature.

This feature should not impact the default (non- '--recursive')
listings however.

=back

=back


Below a few notes on main commands.

=head2 B<create>

The heart of the znapzend backup is the plan. The plan specifies how often
to backup and for how long to keep the backups. A plan is required both for
the source and the destination datasets.

The plan consists of a series of retention periods to interval
associations:

  retA=>intA,retB=>intB,...

Both intervals and retention periods are expressed in standard units of time
or multiples of them. You can use both the full name or a shortcut according
to the following table:

 second|sec|s
 minute|min
 hour|h
 day|d
 week|w
 month|mon|m
 year|y

To keep one copy every 30 minutes for one week, specify:

 1week=>30min

To keep one copy every two days for 10 years:

 10year=>2day

In a minimal setup, you just specify a plan for the B<SRC> fileset. This
will cause snapshots to be taken and destroyed according to the plan. You
can then add one or several destinations (B<DST>) both local (preferably on
a different pool) or remote.

When adding multiple B<DST> entries, each will get labeled for later
identification, optionally you can specify your own label.

=over

=item B<--tsformat>=I<limited-strftime-format>

The B<--tsformat> option specifies how the names of the snapshots are
constructed.

The syntax is L<strftime>-like. The string must consist of the mandatory

 %Y %m %d %H %M %S %z

Optionally,

- _ . :

characters as well as any alphanumeric character are allowed.

If not specified, B<--tsformat> defaults to C<%Y-%m-%d-%H%M%S>.

If B<--tsformat> string is suffixed by a 'Z', times will be in UTC. E.g.:

 --tsformat='%Y-%m-%dT%H:%M:%SZ'

NOTE: that windoz will probably not like the C<:> characters. So if you
intend to browse the snapshots with windoz, you may want to use a different
separator.

=item B<--mbuffer>=I</usr/bin/mbuffer>

DEPRECATED: Specify the path to your copy of the mbuffer utility.

NOTE: with this option, the same path would be used for all remote
destinations - this can misfire if they run different operating systems.

It is currently recommended to define individual B<dst_mbuffer_path>
options for each separate destination in each dataset configuration.
The B<--mbuffer> value would be used as a fallback default for those.

Per legacy-default behavior, the mbuffer program was not used by the
sender (unless using a dedicated port, see below). Nowadays it is
possible to specify it instead of (or in addition to) a destination
side mbuffer, using the B<src_mbuffer_path> in each source dataset
configuration.

=item B<--mbuffer>=I</usr/bin/mbuffer:31337>

DEPRECATED: Specify the path to your copy of the mbuffer utility and
the port used on the destination. Caution: znapzend will use SSH to
set up the remote mbuffer receiver, but will send the snapshot data
stream directly from source mbuffer to destination mbuffer. In other
words, the data stream is B<not> encrypted. Use this only in a trusted
LAN or over VPN, where you can safely avoid the overheads of an SSH
tunnel.

NOTE: with this option, the same path would be used for all remote
destinations as well as the source system - this can misfire if they
run different operating systems.

It is currently recommended to define individual B<*_mbuffer_path>
options for each source and each separate destination in each dataset
configuration. The B<--mbuffer> value would be used as a fallback
default for those (with only path component for the source).

=item B<--mbuffersize>=I<number>{B<b>|B<k>|B<M>|B<G>}

The size of the mbuffer can be set with the B<--mbuffersize> option.  It
supports the following units:

 b, k, M, G

To specify a mbuffer size of 100MB:

 --mbuffersize=100M

If not set, the buffer size defaults to 1GB.

It is currently suggested to define individual B<mbuffer_size> options for
each source and each separate destination in each dataset configuration.
The B<--mbuffer-size> value would be used as a fallback default for those.

=item B<--donotask>

Apply changes immediately. Without being asked if the config is as you
intended it to be.

=item B<--pre-snap-command>=I</path/bin args>, B<--post-snap-command>=I</path/bin args>

Run commands/scripts before and after snapshots are taken on source.
e.g. for database locking/flushing (pre) and unlocking (post).

If you deal with a mariadb/mysql database, you can use

  pre-snap-command  = /opt/oep/mariadb/bin/mysql -e "set autocommit=0;flush tables with read lock;\\! /bin/sleep 600" &  /usr/bin/echo $! > /tmp/mariadblock.pid ; sleep 10
  post-snap-command = /usr/bin/pkill -P `/usr/bin/cat /tmp/mariadblock.pid`;/usr/bin/rm /tmp/mariadblock.pid

to make sure that the on-disk data is consistent when snapshotting. The
lock stays in place only for the duration of the lingering connection
to mysql we need to employ, or until the snapshotting attempt times out.
For this to work, add the root password of your mariadb/mysql database
setup into ~root/.my.cnf and make sure the file permissions are tight ...

The pre and post snapshot commands can find the name and time of the
snapshot in the environment variables I<ZNAP_NAME> and I<ZNAP_TIME>.

=item B<--send-delay>

Specify delay (in seconds) before sending snaps to the destination.
May be useful if you want to control sending time.

=item B<pre-send-command>=I</path/bin args>, B<post-send-command>=I</path/bin args>

Run command/script before and after sending the snapshot to the destination.
Intended to run a remote script via ssh on the destination, e.g. to bring
up a backup disk or server. Or to put a zpool online/offline:

  "ssh root@bserv zpool import -Nf tank"
  "ssh root@bserv zpool export tank"

=back

=head2 B<delete>

to remove configuration from a dataset just give its name

 znapzendzetup delete I<dataset>

the B<delete> function understands the following options:

=over

=item B<--dst>=I<key>

to only remove a destination, specify the key of the destination. Use the
B<list> function to see the keys.

=back

=head2 B<edit>

modify the configuration of a dataset. See the descriptions in the B<create>
function for details.

If B<edit> is used with a source dataset as single argument, properties
can be edited in an editor.

=head2 B<export>

dumps the backup configuration of a dataset

 znapzendzetup export I<dataset>

=head2 B<import>

reads configuration data from a file or STDIN and prints it content

=over

=item B<--write>

actually store the new configuration into the dataset given on the
command line.

=item B<--prop> I<key>="I<value>" [ B<--prop> ... ]

may be called multiple times to override properties in the imported config.

=back

=head1 EXAMPLES

create a complex backup task

    znapzendzetup create --recursive --mbuffer=/opt/omni/bin/mbuffer \
       --mbuffersize=1G --tsformat='%Y-%m-%d-%H%M%S' \
       --pre-snap-command="/bin/sh /usr/local/bin/lock_flush_db.sh" \
       --post-snap-command="/bin/sh /usr/local/bin/unlock_db.sh" \
       SRC '7d=>1h,30d=>4h,90d=>1d' tank/home \
          "/usr/bin/mbuffer" "128M" \
       DST:a '7d=>1h,30d=>4h,90d=>1d,1y=>1w,10y=>1month' backup/home \
       DST:b '7d=>1h,30d=>4h,90d=>1d,1y=>1w,10y=>1month' \
          root@bserv:backup/home \
          "/root/znapzend.sh dst_b pool on" \
          "/root/znapzend.sh dst_b pool off" \
          "/opt/bin64/mbuffer" "4G"


copy the setup from one fileset to another

    znapzendzetup export tank/home | znapzendzetup import --write tank/new_home

=head1 RUNNING AS AN UNPRIVILEGED USER

In order to allow a non-privileged user to use it, the following
permissions are required on the ZFS filesystems:

Sending end: I<destroy,hold,mount,send,snapshot,userprop>
Receiving end: I<create,mount,receive,userprop>

=head1 COPYRIGHT

Copyright (c) 2014 by OETIKER+PARTNER AG. All rights reserved.

=head1 LICENSE

This program is free software: you can redistribute it and/or modify it
under the terms of the GNU General Public License as published by the Free
Software Foundation, either version 3 of the License, or (at your option)
any later version.

This program is distributed in the hope that it will be useful, but WITHOUT
ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
FITNESS FOR A PARTICULAR PURPOSE. See the GNU General Public License for
more details.

You should have received a copy of the GNU General Public License along with
this program. If not, see L<http://www.gnu.org/licenses/>.

=head1 AUTHOR

S<Tobias Oetiker E<lt>tobi@oetiker.chE<gt>>
S<Dominik Hassler E<lt>hadfl@cpan.orgE<gt>>

=head1 HISTORY

2016-09-23 ron Destination pre and post send/receive commands
2014-07-22 had Pre and post snapshot commands
2014-06-29 had Flexible snapshot time format
2014-06-01 had Multi destination backup
2014-05-30 had Initial Version

=cut
